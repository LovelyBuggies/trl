# Model training configuration for GRPO

# Compression settings
compression: "low"  # Options: "high" (4-bit), "medium" (8-bit), or "low" (16-bit)

# Model settings
model_name: "Qwen/Qwen2.5-0.5B"
target_modules: 
  - "q_proj"
  - "k_proj"
  - "v_proj"
  - "o_proj"

# Dataset settings
dataset: "tasksource/mmlu"
mmlu_subset: "all" 
mmlu_split: "dev" 

# Training parameters
batch_size: 2
gradient_accumulation_steps: 8
learning_rate: 1e-5
num_train_epochs: 1000
warmup_steps: 100
max_grad_norm: 0.3

# GRPO specific parameters
max_prompt_length: 128
max_completion_length: 64
num_generations: 4  # Number of generations per prompt (group size)
temperature: 1.0
top_p: 0.9
top_k: 50

# Output settings
output_dir: "./results"
save_dir: "qwen-0.5b-grpo-mmlu-correct"
logging_dir: "./logs"
logging_steps: 10
save_steps: 100
save_total_limit: 3

# Weights & Biases integration
use_wandb: true
wandb_project: "trl"
wandb_entity: "nu-llpr"  # Your Weights & Biases username or organization
run_name: "qwen-0.5b-grpo-mmlu-correct"